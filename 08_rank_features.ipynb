{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b71ae7-f574-4a36-ace3-70f8ddcd5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# President: 2016 (Trump), 2020 (Biden), 2024 (Trump)\n",
    "# U.S. Senate: 2014 (Peters), 2018 (Stabenow), 2020 (Peters), 2024 (Slotkin)\n",
    "# U.S. House: every cycle\n",
    "# State Senate: 2014, 2018, 2022\n",
    "# State House: every cycle\n",
    "\n",
    "ELECTIONS = {}\n",
    "\n",
    "# SKIP FIRST TWO ELECTIONS FOR EVERY OFFICE:\n",
    "ELECTIONS['U.S. House'] =   ['2018', '2020', '2022', '2024']\n",
    "ELECTIONS['State House'] =  ['2018', '2020', '2022', '2024']\n",
    "ELECTIONS['U.S. Senate'] =  ['2020', '2024']\n",
    "ELECTIONS['State Senate'] = ['2022']\n",
    "ELECTIONS['President'] =    ['2024']\n",
    "\n",
    "TARGETS = [\n",
    "    'dem_share',\n",
    "    'rep_share',\n",
    "    'oth_share',\n",
    "    'dem_share_change_curr',\n",
    "    'rep_share_change_curr',\n",
    "    'oth_share_change_curr',\n",
    "    'partisan_temp',\n",
    "    'partisanship_lean_change_amount_curr',\n",
    "    'partisan_temp_change_curr',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b50a1e-df61-4870-a184-fd089359aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_features = [\n",
    "    'standardized_id', 'standardized_id_num',\n",
    "    'aland_tract', 'awater_tract', 'geoid_tract', 'geoidfq_tract', \n",
    "    'geometry', 'geometry_tract', 'name_tract', 'tractce_tract',\n",
    "    'nearest_bound_census_tract', 'nearest_bound_school_district', 'nearest_bound_zipcode',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0355e0ac-e24e-4384-a0ad-65c836958dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d017df-b7a5-43e5-8a50-fe1e53ef75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defb1e7f-d886-42d2-ae1e-f35f11556337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cfc776-3719-4921-8f3e-e423be35ea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ranks features over all historic data for each target. Each target's\n",
    "# most influencial features are saved independently, but without years\n",
    "# or offices in the filename. These are aggregate rankings per target.\n",
    "\n",
    "for target in TARGETS:\n",
    "    print(f'Processing target {target}')\n",
    "    print(f'Num. of offices to process: {len(ELECTIONS)}')\n",
    "\n",
    "    # Best features per target computed by all offices across all years\n",
    "    top_features_list = []\n",
    "    \n",
    "    for key, value in ELECTIONS.items():\n",
    "        print(f'Num. of years to process: {len(value)}')\n",
    "        \n",
    "        OFFICES = [key]\n",
    "        YEARS = value\n",
    "    \n",
    "        print(f'Process office(s): {key} for year(s): {', '.join(YEARS)}')\n",
    "        \n",
    "        # # Rank all features for the target defined above\n",
    "        # # using several different metrics as well\n",
    "        # # as an average score across metrics to help\n",
    "        # # test many different combinations of features\n",
    "        # # and targets.\n",
    "        for year in YEARS:\n",
    "            print(f'Processing year {year}...')\n",
    "            \n",
    "            for office in OFFICES:\n",
    "                print(f'Processing year {office}...')\n",
    "    \n",
    "                office = office.replace(' ', '_').replace('.', '')\n",
    "                \n",
    "                df = pd.read_csv(f'data/generated_data/07_ml_features_{year}_{office}_with_geometry.csv', low_memory=False)\n",
    "                # df = df.drop(columns=drop_features)\n",
    "                \n",
    "                # Target and features\n",
    "                y = df[target]\n",
    "        \n",
    "                # Categorical targets need to be encoded\n",
    "                if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "                    label_encoder = LabelEncoder()\n",
    "                    y = pd.Series(label_encoder.fit_transform(y), name=target)\n",
    "                \n",
    "                X = df.drop(columns=[target])\n",
    "        \n",
    "                # Combine X and y, drop rows where y is NaN\n",
    "                df_model = pd.concat([X, y], axis=1)\n",
    "                df_model = df_model.dropna(subset=[target])\n",
    "                \n",
    "                # Separate again\n",
    "                y = df_model[target]\n",
    "                X = df_model.drop(columns=[target])\n",
    "                \n",
    "                # Keep only numeric features\n",
    "                X_numeric = X.select_dtypes(include=[np.number]).copy()\n",
    "                \n",
    "                # Drop any columns with all NaNs or constant values\n",
    "                X_numeric = X_numeric.dropna(axis=1, how='all')\n",
    "                X_numeric = X_numeric.loc[:, X_numeric.nunique() > 1]\n",
    "                \n",
    "                # Fill remaining NaNs with mean\n",
    "                X_numeric = X_numeric.fillna(X_numeric.mean(numeric_only=True))\n",
    "                \n",
    "                # Train-test split\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X_numeric, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "                # Begin running models to compute corresonding accuracies.\n",
    "                \n",
    "                print('Running Correlation')\n",
    "                correlations =  X_numeric.corrwith(y).abs().sort_values(ascending=False)\n",
    "                \n",
    "                print('Running Random Forest')\n",
    "                rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=10, max_features='sqrt')\n",
    "                rf.fit(X_train, y_train)\n",
    "                rf_importances = pd.Series(rf.feature_importances_, index=X_numeric.columns)\n",
    "                \n",
    "                print('Running LassoCV')\n",
    "                scaler = StandardScaler()\n",
    "                X_scaled = scaler.fit_transform(X_numeric)\n",
    "                lasso = LassoCV(cv=5, random_state=42, max_iter=10000)\n",
    "                lasso.fit(X_scaled, y)\n",
    "                lasso_importances = pd.Series(np.abs(lasso.coef_), index=X_numeric.columns)\n",
    "                \n",
    "                print('Running Mutual Information')\n",
    "                mi = mutual_info_regression(X_numeric, y, random_state=42)\n",
    "                mi_importances = pd.Series(mi, index=X_numeric.columns)\n",
    "                \n",
    "                print('Running SHAP')\n",
    "                explainer = shap.Explainer(rf, X_train)\n",
    "                shap_values = explainer(X_test, check_additivity=False)\n",
    "                shap_importances = pd.Series(np.abs(shap_values.values).mean(0), index=X_numeric.columns)\n",
    "                \n",
    "                df_importances = pd.DataFrame({\n",
    "                    'Correlation': correlations,\n",
    "                    'RandomForest': rf_importances,\n",
    "                    'LassoCV': lasso_importances,\n",
    "                    'MutualInfo': mi_importances,\n",
    "                    'SHAP': shap_importances\n",
    "                })\n",
    "                \n",
    "                # df_importances['Average'] = df_importances.mean(axis=1)  # Commented out b/c skip average for each office.\n",
    "                \n",
    "                df_importances = df_importances.reset_index()\n",
    "                df_importances.rename(columns={'index': 'Feature name'}, inplace=True)\n",
    "        \n",
    "                top_features_list.append(df_importances)\n",
    "        \n",
    "    # Combine the feature columns\n",
    "    df_combined = pd.concat(top_features_list, axis=0)\n",
    "    \n",
    "    # Aggregate features to compute averages.\n",
    "    df_aggregated = df_combined.groupby('Feature name').mean(numeric_only=True).reset_index()\n",
    "    df_aggregated['Average'] = df_aggregated.select_dtypes(include=[np.number]).mean(axis=1) # Average across all offices.\n",
    "    df_aggregated = df_aggregated.sort_values(by='Average', ascending=False)\n",
    "    \n",
    "    df_aggregated.to_csv(f'data/generated_data/df_importances_{target}.csv', index=False)\n",
    "\n",
    "    # Plot features\n",
    "    import matplotlib.pyplot as plt\n",
    "    top_n = 20\n",
    "    df_plot = df_aggregated.head(top_n).set_index('Feature name')\n",
    "    \n",
    "    # Drop 'Average' to plot metrics separately\n",
    "    metrics = df_plot.drop(columns='Average')\n",
    "    \n",
    "    # Plot\n",
    "    ax = metrics.plot(kind='barh', figsize=(12, 10), width=0.85)\n",
    "    plt.gca().invert_yaxis()  # highest at top\n",
    "    plt.title(f'Top {top_n} Feature Importances by Metric')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.legend(title='Metric')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'output/figures/features_ranking_{target}.png')\n",
    "    plt.close()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4819f11-ed86-40b0-924e-cec88d9a38ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
